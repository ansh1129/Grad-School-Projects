{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import glob\n",
    "import pickle\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 1000\n",
    "n_top_words = 20\n",
    "n_components = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = glob.glob(\"*.csv\")\n",
    "fs.remove('aluminum_5yrs_seekingalpha.csv')\n",
    "dfs = []\n",
    "for f in fs:\n",
    "    dfs.append(pd.read_csv(f))\n",
    "df = pd.concat(dfs).reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Dude, You're Not Getting DELL...Or AUTO</td>\n",
       "      <td>Mar.18.13</td>\n",
       "      <td>(At Least Not At These Prices)Despite differen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Critical Analysis Of Dell Buyout Plan Shows Hi...</td>\n",
       "      <td>Mar.14.13</td>\n",
       "      <td>The media is currently focused on the saga of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Value Of Dell Using The EBIT Multiple Valu...</td>\n",
       "      <td>Mar.14.13</td>\n",
       "      <td>Let me go through a EBIT multiple valuation me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Dell LBO Deal Structure - Like Buying A Rental...</td>\n",
       "      <td>Feb. 7.13</td>\n",
       "      <td>Henry Blodget is pulling on exactly the right ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Billionaire Carl Icahn Moving Into Multilevel-...</td>\n",
       "      <td>Mar. 12, 2013 8:55 AM ET</td>\n",
       "      <td>In the view of many investors, billionaire Car...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                              title  \\\n",
       "0      0            Dude, You're Not Getting DELL...Or AUTO   \n",
       "1      1  Critical Analysis Of Dell Buyout Plan Shows Hi...   \n",
       "2      2  The Value Of Dell Using The EBIT Multiple Valu...   \n",
       "3      3  Dell LBO Deal Structure - Like Buying A Rental...   \n",
       "4      4  Billionaire Carl Icahn Moving Into Multilevel-...   \n",
       "\n",
       "                       date                                               body  \n",
       "0                 Mar.18.13  (At Least Not At These Prices)Despite differen...  \n",
       "1                 Mar.14.13  The media is currently focused on the saga of ...  \n",
       "2                 Mar.14.13  Let me go through a EBIT multiple valuation me...  \n",
       "3                 Feb. 7.13  Henry Blodget is pulling on exactly the right ...  \n",
       "4  Mar. 12, 2013 8:55 AM ET  In the view of many investors, billionaire Car...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat(dfs)\n",
    "df.reset_index(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1854, 4)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n",
    "    \n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic {}:\".format(topic_idx))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "        \n",
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key]\n",
    "    \n",
    "class Predictor(BaseEstimator, ClassifierMixin): \n",
    "    def __init__(self, top_n=5, debug=False):\n",
    "        self.top_n = top_n\n",
    "        self.debug = debug\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        return self\n",
    "    \n",
    "    def _flatten(self, l):\n",
    "        return list(itertools.chain(*l))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        m = np.matmul(self.X, X.T).T \n",
    "        results = []\n",
    "        for idx, row in enumerate(np.argsort(m)):\n",
    "            top_idxs = list(reversed(row[-self.top_n:]))\n",
    "            results.append(self.X[top_idxs])\n",
    "        return np.array(results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Topicer():\n",
    "    def __init__(self, debug=False):\n",
    "        self.selector = ItemSelector(key='body')\n",
    "        \n",
    "        \"\"\"\n",
    "        self.words = CountVectorizer(ngram_range=(1,2), max_df=0.95, min_df=2,\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english')\n",
    "        self.transformer = LatentDirichletAllocation(n_components=n_components, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.words = TfidfVectorizer(ngram_range=(1,1), max_df=0.95, min_df=2,\n",
    "                                   max_features=n_features,\n",
    "                                   stop_words='english')\n",
    "        \n",
    "        self.transformer = NMF(n_components=n_components, random_state=1, \n",
    "                  alpha=.1, l1_ratio=.5, init='nndsvd')\n",
    "        \n",
    "        self.classifier = Predictor(top_n=5, debug=debug)\n",
    "        \n",
    "    def _preprocess_fit(self, X):\n",
    "        r = self.selector.transform(X)\n",
    "        r = self.words.fit_transform(r)\n",
    "        self.transformer.fit(r)\n",
    "        r = self.transformer.transform(r)\n",
    "        return r\n",
    "    \n",
    "    def _preprocess_predict(self, X):\n",
    "        r = self.selector.transform(X)\n",
    "        r = self.words.transform(r)\n",
    "        r = self.transformer.transform(r)\n",
    "        return r\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        r = self._preprocess_fit(X)\n",
    "        self.X = r\n",
    "        self.y = y\n",
    "        self.classifier.fit(self.X, self.y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        r = self._preprocess_predict(X)\n",
    "        return self.classifier.predict(r)\n",
    "    \n",
    "    def display_topics(self, no_top_words):\n",
    "        model = self.transformer\n",
    "        feature_names = self.words.get_feature_names()\n",
    "        for topic_idx, topic in enumerate(model.components_):\n",
    "            print(\"Topic {}:\".format(topic_idx))\n",
    "            print(\" \".join([feature_names[i]\n",
    "                            for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Topicer()\n",
    "r = t.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "revenue year quarter growth earnings sales billion million company share revenues fiscal reported decline results eps guidance operating margin report adjusted increase total fourth segment line business net expected q3\n",
      "Topic 1:\n",
      "ibm business strategic imperatives revenue rometty years blue blockchain growth company cloud mainframe big machines businesses hardware billion past computing analytics international tech nyse time long buybacks declines areas technology\n",
      "Topic 2:\n",
      "hp pc enterprise printing whitman hpq printers split printer lenovo hewlett sales packard pcs business ceo billion hardware personal meg unit shipments businesses year shareholders market gartner quarter xerox new\n",
      "Topic 3:\n",
      "dividend yield payout dividends stocks income yields growth ratio earnings high paying investors years yielding current flow payments list increases year company annual increase companies look free past ratios stock\n",
      "Topic 4:\n",
      "dell mr michael said private deal buyout technologies firm equity corp computer chief group billion founder according people partners executive maker following shareholders investment million fund company home public street\n",
      "Topic 5:\n",
      "seagate stx technology drive nasdaq hard ripple storage drives shares demand hdd capacity previously shipments pc disk gross quarter data market q3 results earnings decline fell says read buyout q4\n",
      "Topic 6:\n",
      "western digital wdc sandisk corporation hard nasdaq drive acquisition market hdd target nyse share following shares deal etf debt transfer flash analyst sndk merger rival strong previously announced close price\n",
      "Topic 7:\n",
      "storage drives ssd hdd ssds flash hdds disk hard state nand solid sandisk drive market data marvell wd memory enterprise cost devices products seagate capacity manufacturers stx shipments demand technologies\n",
      "Topic 8:\n",
      "micron nand memory sandisk dram mu samsung 3d nasdaq chips otc intel technology flash prices supply semiconductor sndk cost production business intc 2016 wd industry chip electronics demand ssds partnership\n",
      "Topic 9:\n",
      "hpe enterprise packard hewlett etf whitman spin nyse meg software portfolio services micro eps earnings focus 2017 hpq following deal right ceo press q3 business conference hybrid shares consensus split\n",
      "Topic 10:\n",
      "3d printing stratasys systems printer printers industry technology technologies multi hpq hp manufacturing growth stocks space parts 2014 applications hewlett packard process revenue competition market speed potential faster industrial production\n",
      "Topic 11:\n",
      "microsoft windows pc laptop google msft laptops tablet tablets computers android devices pro pcs computer 10 software users operating office lenovo mobile smartphone desktop china smartphones great like nasdaq core\n",
      "Topic 12:\n",
      "stocks stock 10 tom david advisor right better investors just fool motley investing gardner returns buy buys wasn tripled revealed tip decade 2018 market best think april newsletter geniuses pay\n",
      "Topic 13:\n",
      "gaap measures financial statements non chief conference president today information executive investor officer vice 2017 forward quarter looking fiscal turn website question sec available earnings guidance results 2016 posted answer\n",
      "Topic 14:\n",
      "dogs dow index nasdaq price stocks 100 500 yield upside target dividend paying analyst 30 results prices plus alpha sector estimate article series combined dividends specific highest nyse market yielding\n",
      "Topic 15:\n",
      "intel amd server processors chips intc qualcomm power market servers nasdaq chip pc mobile devices center data x86 iot tablet performance sales micro semiconductor tablets based lenovo centers pcs segment\n",
      "Topic 16:\n",
      "toshiba memory wdc otcpk chip sale unit nand flash western digital otc deal sell previously billion supply production funds latest read wd samsung business chips equity march key stake 18\n",
      "Topic 17:\n",
      "apple iphone aapl nasdaq google samsung smartphone lenovo electronics pc tech android jobs mobile chinese tablet products steve market hardware smartphones tablets product pro success otc new consumers launch devices\n",
      "Topic 18:\n",
      "buffett berkshire hathaway warren shares stake nyse investment value position shareholders stock holdings 2011 portfolio mr shareholder ibm book investor share buying years annual billion price sold investing investments money\n",
      "Topic 19:\n",
      "emc vmware dell tracking merger corp storage shares deal acquisition billion stock shareholders transaction class said held common combined flash tech 60 servers announced 24 reported outstanding september information share\n",
      "Topic 20:\n",
      "cisco security networking networks network enterprise server iot systems wireless oracle hardware market nasdaq center threat data companies internet software provider growing growth solutions tech offerings servers revenues acquisition billion\n",
      "Topic 21:\n",
      "cloud amazon services data computing software service platform infrastructure solutions storage public enterprise hybrid billion microsoft security analytics hardware google business systems applications companies big servers customers businesses providers server\n",
      "Topic 22:\n",
      "watson ai ibm healthcare data cognitive machine health intelligence platform analytics new big technology information computer specific research game computing use financial ago driving project iot used computers provided make\n",
      "Topic 23:\n",
      "cash flow debt free value billion company stock share shareholders shares capital equity return price balance net buybacks sheet ratio wdc valuation deal management outstanding operating million buyback xerox sandisk\n",
      "Topic 24:\n",
      "company companies nyse market value stock years nasdaq new time business price industry investors technology shares growth article 000 world million investment like long management high data china money just\n"
     ]
    }
   ],
   "source": [
    "t.display_topics(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "lda_pipeline = Pipeline([\n",
    "    ('selector', ItemSelector(key='body')),\n",
    "    ('words', CountVectorizer(ngram_range=(1,2), max_df=0.95, min_df=2,\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english')),\n",
    "    ('transform', LatentDirichletAllocation(n_components=n_components, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)),\n",
    "    ('classify', Predictor(top_n=5))\n",
    "])\n",
    "\n",
    "nmf_pipeline = Pipeline([\n",
    "    ('selector', ItemSelector(key='body')),\n",
    "    ('words', TfidfVectorizer(ngram_range=(1,2), max_df=0.95, min_df=2,\n",
    "                                   max_features=n_features,\n",
    "                                   stop_words='english')),\n",
    "    ('transform', NMF(n_components=n_components, random_state=1, \n",
    "                  alpha=.1, l1_ratio=.5, init='nndsvd')),\n",
    "    ('classify', Predictor(top_n=5))\n",
    "])\n",
    "lda = lda_pipeline.fit(X_train, y_train)\n",
    "nmf = nmf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "lda_res = lda_pipeline.predict(X_test[:2])\n",
    "nmf_res = nmf_pipeline.predict(X_test[:2])\n",
    "print(lda_res)\n",
    "print(nmf_res)\n",
    "print(X_test[:2]['tags'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
